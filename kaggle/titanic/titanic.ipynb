{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":18,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/gender_submission.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_raw = pd.read_csv('/kaggle/input/titanic/train.csv')\ndata_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n\nX = data_raw.copy(deep=True).drop('Survived', axis=1)\ny = data_raw.copy(deep=True)['Survived']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_test, y_val = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\ndata_val = pd.concat([X_val, y_val], axis=1)\n\ndata_copy = data_raw.copy(deep=True)\nprint(data_raw.info())\ndata_val.sample(10)","execution_count":19,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\nNone\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"     PassengerId  Pclass                              Name     Sex   Age  \\\n728          729       2   Bryhl, Mr. Kurt Arnold Gottfrid    male  25.0   \n784          785       3                  Ali, Mr. William    male  25.0   \n5              6       3                  Moran, Mr. James    male   NaN   \n266          267       3         Panula, Mr. Ernesti Arvid    male  16.0   \n570          571       2                Harris, Mr. George    male  62.0   \n631          632       3       Lundahl, Mr. Johan Svensson    male  51.0   \n310          311       1    Hays, Miss. Margaret Bechstein  female  24.0   \n681          682       1                Hassab, Mr. Hammad    male  27.0   \n561          562       3                 Sivic, Mr. Husein    male  40.0   \n399          400       2  Trout, Mrs. William H (Jessie L)  female  28.0   \n\n     SibSp  Parch              Ticket     Fare Cabin Embarked  Survived  \n728      1      0              236853  26.0000   NaN        S         0  \n784      0      0  SOTON/O.Q. 3101312   7.0500   NaN        S         0  \n5        0      0              330877   8.4583   NaN        Q         0  \n266      4      1             3101295  39.6875   NaN        S         0  \n570      0      0         S.W./PP 752  10.5000   NaN        S         1  \n631      0      0              347743   7.0542   NaN        S         0  \n310      0      0               11767  83.1583   C54        C         1  \n681      0      0            PC 17572  76.7292   D49        C         1  \n561      0      0              349251   7.8958   NaN        S         0  \n399      0      0              240929  12.6500   NaN        S         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>728</th>\n      <td>729</td>\n      <td>2</td>\n      <td>Bryhl, Mr. Kurt Arnold Gottfrid</td>\n      <td>male</td>\n      <td>25.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>236853</td>\n      <td>26.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>784</th>\n      <td>785</td>\n      <td>3</td>\n      <td>Ali, Mr. William</td>\n      <td>male</td>\n      <td>25.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SOTON/O.Q. 3101312</td>\n      <td>7.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>3</td>\n      <td>Moran, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>266</th>\n      <td>267</td>\n      <td>3</td>\n      <td>Panula, Mr. Ernesti Arvid</td>\n      <td>male</td>\n      <td>16.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3101295</td>\n      <td>39.6875</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>570</th>\n      <td>571</td>\n      <td>2</td>\n      <td>Harris, Mr. George</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>S.W./PP 752</td>\n      <td>10.5000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>631</th>\n      <td>632</td>\n      <td>3</td>\n      <td>Lundahl, Mr. Johan Svensson</td>\n      <td>male</td>\n      <td>51.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>347743</td>\n      <td>7.0542</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>310</th>\n      <td>311</td>\n      <td>1</td>\n      <td>Hays, Miss. Margaret Bechstein</td>\n      <td>female</td>\n      <td>24.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11767</td>\n      <td>83.1583</td>\n      <td>C54</td>\n      <td>C</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>682</td>\n      <td>1</td>\n      <td>Hassab, Mr. Hammad</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17572</td>\n      <td>76.7292</td>\n      <td>D49</td>\n      <td>C</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>561</th>\n      <td>562</td>\n      <td>3</td>\n      <td>Sivic, Mr. Husein</td>\n      <td>male</td>\n      <td>40.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>349251</td>\n      <td>7.8958</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>400</td>\n      <td>2</td>\n      <td>Trout, Mrs. William H (Jessie L)</td>\n      <td>female</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240929</td>\n      <td>12.6500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train columns with null values:\\n', (data_copy.isnull().sum() / len(data_copy)).sort_values(ascending=False))\nprint(\"-\"*10)\nprint('Validation columns with null values:\\n', (data_val.isnull().sum() / len(data_val)).sort_values(ascending=False))\n","execution_count":20,"outputs":[{"output_type":"stream","text":"Train columns with null values:\n Cabin          0.771044\nAge            0.198653\nEmbarked       0.002245\nFare           0.000000\nTicket         0.000000\nParch          0.000000\nSibSp          0.000000\nSex            0.000000\nName           0.000000\nPclass         0.000000\nSurvived       0.000000\nPassengerId    0.000000\ndtype: float64\n----------\nValidation columns with null values:\n Cabin          0.770950\nAge            0.201117\nSurvived       0.000000\nEmbarked       0.000000\nFare           0.000000\nTicket         0.000000\nParch          0.000000\nSibSp          0.000000\nSex            0.000000\nName           0.000000\nPclass         0.000000\nPassengerId    0.000000\ndtype: float64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw.describe(include='all')","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"        PassengerId    Survived      Pclass                            Name  \\\ncount    891.000000  891.000000  891.000000                             891   \nunique          NaN         NaN         NaN                             891   \ntop             NaN         NaN         NaN  Eustis, Miss. Elizabeth Mussey   \nfreq            NaN         NaN         NaN                               1   \nmean     446.000000    0.383838    2.308642                             NaN   \nstd      257.353842    0.486592    0.836071                             NaN   \nmin        1.000000    0.000000    1.000000                             NaN   \n25%      223.500000    0.000000    2.000000                             NaN   \n50%      446.000000    0.000000    3.000000                             NaN   \n75%      668.500000    1.000000    3.000000                             NaN   \nmax      891.000000    1.000000    3.000000                             NaN   \n\n         Sex         Age       SibSp       Parch Ticket        Fare  \\\ncount    891  714.000000  891.000000  891.000000    891  891.000000   \nunique     2         NaN         NaN         NaN    681         NaN   \ntop     male         NaN         NaN         NaN   1601         NaN   \nfreq     577         NaN         NaN         NaN      7         NaN   \nmean     NaN   29.699118    0.523008    0.381594    NaN   32.204208   \nstd      NaN   14.526497    1.102743    0.806057    NaN   49.693429   \nmin      NaN    0.420000    0.000000    0.000000    NaN    0.000000   \n25%      NaN   20.125000    0.000000    0.000000    NaN    7.910400   \n50%      NaN   28.000000    0.000000    0.000000    NaN   14.454200   \n75%      NaN   38.000000    1.000000    0.000000    NaN   31.000000   \nmax      NaN   80.000000    8.000000    6.000000    NaN  512.329200   \n\n              Cabin Embarked  \ncount           204      889  \nunique          147        3  \ntop     C23 C25 C27        S  \nfreq              4      644  \nmean            NaN      NaN  \nstd             NaN      NaN  \nmin             NaN      NaN  \n25%             NaN      NaN  \n50%             NaN      NaN  \n75%             NaN      NaN  \nmax             NaN      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891</td>\n      <td>891.000000</td>\n      <td>204</td>\n      <td>889</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>891</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>681</td>\n      <td>NaN</td>\n      <td>147</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Eustis, Miss. Elizabeth Mussey</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1601</td>\n      <td>NaN</td>\n      <td>C23 C25 C27</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>577</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>644</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>NaN</td>\n      <td>32.204208</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>NaN</td>\n      <td>49.693429</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>7.910400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>14.454200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>31.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>512.329200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_drop = ['Cabin', 'PassengerId', 'Ticket'] # drop Cabin due to high number of nan, PassengerId and Ticket carry no useful information\nX_train.drop(cols_to_drop, axis=1, inplace = True)\ndata_val.drop(cols_to_drop, axis=1, inplace = True)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train columns with null values:\\n', (X_train.isnull().sum()).sort_values(ascending=False))\nprint(\"-\"*10)\nprint('Validation columns with null values:\\n', (data_val.isnull().sum()).sort_values(ascending=False))\n\nX_train.dtypes","execution_count":29,"outputs":[{"output_type":"stream","text":"Train columns with null values:\n Age         0.158249\nEmbarked    0.002245\nFare        0.000000\nParch       0.000000\nSibSp       0.000000\nSex         0.000000\nName        0.000000\nPclass      0.000000\ndtype: float64\n----------\nValidation columns with null values:\n Age         0.201117\nSurvived    0.000000\nEmbarked    0.000000\nFare        0.000000\nParch       0.000000\nSibSp       0.000000\nSex         0.000000\nName        0.000000\nPclass      0.000000\ndtype: float64\n","name":"stdout"},{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"Pclass        int64\nName         object\nSex          object\nAge         float64\nSibSp         int64\nParch         int64\nFare        float64\nEmbarked     object\ndtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# based on the fact that Embarked is the only categorical feature that has missing values, we will use mode to\n# fill in said missing values\n# for all others we will use the median, not the mean, to account for outliers\n# we will also scale all the data\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\n\nscaler = StandardScaler()\nmedian_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\nmode_imputer = SimpleImputer(missing_values=np.nan, strategy='mode')\n\nX_train['Embarked'] = mode_imputer.fit_transform(X_train['Embarked'])\nX_train\n\n\ndata_cleaner = [data_copy, data_val]\n\n","execution_count":24,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}